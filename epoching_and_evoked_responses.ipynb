{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c20d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules and matplotlib PyQt5 backend\n",
    "import pathlib\n",
    "import matplotlib\n",
    "\n",
    "import mne\n",
    "import mne_bids\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5ee988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_meg.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading events from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_events.tsv.\n",
      "Reading channel info from out_data\\sample_BIDS\\sub-01\\ses-01\\meg\\sub-01_ses-01_task-audiovisual_run-01_channels.tsv.\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_11392\\4265811384.py:13: RuntimeWarning: The unit for channel(s) STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, STI 015, STI 016 has changed from V to NA.\n",
      "  raw = mne_bids.read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 19821 samples (33.001 sec)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['Auditory/Left', 'Auditory/Right', 'Button', 'Smiley', 'Visual/Left', 'Visual/Right']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 366 out of 366 | elapsed:    9.2s finished\n"
     ]
    }
   ],
   "source": [
    "#BIDS: Brain Imaging Data Structure to organise EEG datasets\n",
    "#specifying input folder (sample bids data)\n",
    "bids_root = pathlib.Path('out_data/sample_BIDS')\n",
    "\n",
    "#bids info\n",
    "bids_path = mne_bids.BIDSPath(subject='01',\n",
    "                              session='01',\n",
    "                              task='audiovisual',\n",
    "                              run='01',\n",
    "                              datatype='meg',\n",
    "                              root=bids_root)\n",
    "#reading the input\n",
    "raw = mne_bids.read_raw_bids(bids_path)\n",
    "#loading the data\n",
    "raw.load_data()\n",
    "#filtering\n",
    "raw.filter(l_freq=0.1, h_freq=40)\n",
    "#extracting events\n",
    "events, event_id = mne.events_from_annotations(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58ce4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Auditory/Left': 1,\n",
       " 'Auditory/Right': 2,\n",
       " 'Button': 3,\n",
       " 'Smiley': 4,\n",
       " 'Visual/Left': 5,\n",
       " 'Visual/Right': 6}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experimental events are found like stimulus, trigger channels, etc\n",
    "#events are encoded with event ids which are not readable by humans\n",
    "#therefore we create a dictionary to map these event ids to readable forms\n",
    "#events are needed to make epochs\n",
    "event_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b212dabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "320 matching events found\n",
      "Setting baseline interval to [-0.2996928197375818, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "3 projection items activated\n",
      "Using data from preloaded Raw for 320 events and 481 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>Auditory/Left: 72<br/>Auditory/Right: 73<br/>Button: 16<br/>Smiley: 15<br/>Visual/Left: 73<br/>Visual/Right: 71</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.300 – 0.499 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.300 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  320 events (all good), -0.299693 - 0.499488 sec, baseline -0.299693 – 0 sec, ~441.9 MB, data loaded,\n",
       " 'Auditory/Left': 72\n",
       " 'Auditory/Right': 73\n",
       " 'Button': 16\n",
       " 'Smiley': 15\n",
       " 'Visual/Left': 73\n",
       " 'Visual/Right': 71>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#where epoch starts (before the event)\n",
    "tmin = -0.3\n",
    "#where epoch ends (after the event)\n",
    "tmax = 0.5\n",
    "baseline = (None, 0)\n",
    "#epochs slice the continuous data into small time segments\n",
    "#creating epochs\n",
    "epochs = mne.Epochs(raw,\n",
    "                    events=events,\n",
    "                    event_id=event_id,\n",
    "                    tmin=tmin,\n",
    "                    tmax=tmax,\n",
    "                    baseline=baseline,\n",
    "                    preload=True)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6091e1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MNEBrowseFigure size 800x749 with 4 Axes>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plotting EEG epochs\n",
    "epochs.plot(picks='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9865596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "#saving the data\n",
    "epochs.save(pathlib.Path('out_data') / 'epochs_epo.fif', \n",
    "            overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ea78741",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking auditory and visual event avg and feeding to a variable\n",
    "evoked_auditory = epochs['Auditory'].average()\n",
    "evoked_visual = epochs['Visual'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "228139b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Removing projector <Projection | PCA-v1, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v2, active : True, n_channels : 102>\n",
      "Removing projector <Projection | PCA-v3, active : True, n_channels : 102>\n",
      "Dropped 0 epochs: \n",
      "The following epochs were marked as bad and are dropped:\n",
      "[]\n",
      "Channels marked as bad:\n",
      "['MEG 2443', 'EEG 053']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x420 with 7 Axes>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joint plot for auditory of eeg signals in the time domain\n",
    "evoked_auditory.plot_joint(picks='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e4c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2330df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf6db84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68d393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
